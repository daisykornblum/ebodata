{
 "metadata": {
  "name": "",
  "signature": "sha256:08e1789014983fe696e5785b0dc6397321892d5c26940dc6eda6125977f77fce"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Basic text analysis snippets"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Word frequency counter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute a collection of all words from all tweets\n",
      "words = [ w \n",
      "          for t in ebodata.txt \n",
      "              for w in t.split() ]\n",
      "\n",
      "# Get most used words in tweets\n",
      "\n",
      "from collections import Counter\n",
      "    \n",
      "# Get list of most common words and counts\n",
      "\n",
      "wordlist = []\n",
      "# Top 500 words\n",
      "for item in [words]:\n",
      "    c = Counter(item)\n",
      "    wordlist = c.most_common()[:500]\n",
      "\n",
      "from pandas import DataFrame\n",
      "wordcount = DataFrame(wordlist)\n",
      "wordcount.columns = ['Words', 'Count']\n",
      "wordcount.to_excel('wordcount.xlsx')\n",
      "wordcount\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'ebodata' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-834818ac560e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute a collection of all words from all tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m words = [ w \n\u001b[0;32m----> 3\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mebodata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m               for w in t.split() ]\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'ebodata' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "%matplotlib inline\n",
      "word_counts = sorted(Counter(words).values(), reverse=True)\n",
      "\n",
      "plt.loglog(word_counts)\n",
      "plt.ylabel(\"Freq\")\n",
      "plt.xlabel(\"Word Rank\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Lexical diversity"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A function for computing lexical diversity\n",
      "def lexical_diversity(tokens):\n",
      "    return 1.0*len(set(tokens))/len(tokens) \n",
      "\n",
      "# A function for computing the average number of words per tweet\n",
      "def average_words(statuses):\n",
      "    total_words = sum([ len(s.split()) for s in statuses ]) \n",
      "    return 1.0*total_words/len(statuses)\n",
      "\n",
      "print lexical_diversity(words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}